{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository(Evaluation DATASET)\n",
        "!git clone https://github.com/younes2808/SmallImage2LatexOCR.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEvWWebb5m5m",
        "outputId": "b20b02ac-5c3a-4d20-e327-c768f4e28024"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SmallImage2LatexOCR'...\n",
            "remote: Enumerating objects: 483, done.\u001b[K\n",
            "remote: Counting objects: 100% (483/483), done.\u001b[K\n",
            "remote: Compressing objects: 100% (471/471), done.\u001b[K\n",
            "remote: Total 483 (delta 18), reused 434 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (483/483), 570.93 KiB | 15.43 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, VisionEncoderDecoderModel, AutoImageProcessor\n",
        "import difflib\n",
        "import time\n",
        "\n",
        "# Initialize MixTex Model\n",
        "feature_extractor = AutoImageProcessor.from_pretrained(\"MixTex/ZhEn-Latex-OCR\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"MixTex/ZhEn-Latex-OCR\", max_len=296)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"MixTex/ZhEn-Latex-OCR\")\n",
        "\n",
        "# Function to clean OCR output\n",
        "def clean_ocr_output(ocr_latex):\n",
        "    \"\"\"\n",
        "    Clean the OCR LaTeX output by removing unnecessary tags and formatting.\n",
        "    \"\"\"\n",
        "    ocr_latex = ocr_latex.replace(\"<s><s>\\\\begin{align*}\", \"\").replace(\"\\\\end{align*}</s>\", \"\")\n",
        "    ocr_latex = ocr_latex.strip()  # Remove leading/trailing whitespace\n",
        "    return ocr_latex\n",
        "\n",
        "# Function to normalize LaTeX\n",
        "def normalize_latex(latex_string):\n",
        "    \"\"\"\n",
        "    Normalize the LaTeX string by removing unnecessary spaces and ensuring consistent formatting.\n",
        "    \"\"\"\n",
        "    latex_string = latex_string.replace(\" \", \"\").replace(\"\\\\,\", \"\").replace(\"\\\\ \", \"\")\n",
        "    latex_string = latex_string.replace(\"...\", \"\\\\dots\")  # Normalize ellipsis\n",
        "    return latex_string\n",
        "\n",
        "# Function to compare LaTeX strings\n",
        "def compare_latex(correct_latex, ocr_latex):\n",
        "    \"\"\"\n",
        "    Compare the correctness of the OCR output with the correct LaTeX expression.\n",
        "    \"\"\"\n",
        "    # Normalize both strings\n",
        "    normalized_correct = normalize_latex(correct_latex)\n",
        "    normalized_ocr = normalize_latex(ocr_latex)\n",
        "\n",
        "    # Use difflib to compare the two strings\n",
        "    diff = difflib.ndiff(normalized_correct, normalized_ocr)\n",
        "    similarity = sum(1 for c in diff if c[0] == ' ') / len(normalized_correct)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Function to run OCR and compare results\n",
        "def run_ocr_and_compare(img_path, txt_path):\n",
        "    \"\"\"\n",
        "    Run OCR on the image and compare the result with the corresponding LaTeX in the text file.\n",
        "    \"\"\"\n",
        "    # Start timer to measure OCR processing time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Open the image\n",
        "    img = Image.open(img_path)\n",
        "    pixel_values = feature_extractor(img, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "    # Generate OCR output\n",
        "    with torch.no_grad():\n",
        "        ocr_output = model.generate(pixel_values)\n",
        "        ocr_latex = tokenizer.decode(ocr_output[0], skip_special_tokens=True)\n",
        "        ocr_latex = clean_ocr_output(ocr_latex)  # Clean the OCR output\n",
        "\n",
        "    # End timer to calculate elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Read the correct LaTeX from the corresponding .txt file\n",
        "    with open(txt_path, \"r\") as file:\n",
        "        correct_latex = file.read().strip()\n",
        "\n",
        "    # Compare the LaTeX strings\n",
        "    similarity_score = compare_latex(correct_latex, ocr_latex)\n",
        "\n",
        "    return similarity_score, ocr_latex, correct_latex, elapsed_time\n",
        "\n",
        "# Function to process dataset\n",
        "def process_dataset(dataset_dir, output_file):\n",
        "    \"\"\"\n",
        "    Process the entire dataset, comparing OCR results with ground truth LaTeX and logging results.\n",
        "    \"\"\"\n",
        "    passed_count = 0\n",
        "    total_time = 0\n",
        "    total_comparisons = 0\n",
        "    total_similarity = 0\n",
        "\n",
        "    # Open the output file to write results\n",
        "    with open(output_file, 'w') as f:\n",
        "        # Loop through all folders from 000 to 100\n",
        "        for i in range(101):  # 0 to 100\n",
        "            folder_name = f\"{str(i).zfill(3)}\"  # Format as 000, 001, ..., 100\n",
        "            folder_path = os.path.join(dataset_dir, folder_name)\n",
        "\n",
        "            if os.path.isdir(folder_path):  # Process only directories\n",
        "                f.write(f\"Processing folder: {folder_name}\\n\")\n",
        "                # Loop through all image files from 000.png to 100.png\n",
        "                for j in range(101):  # 0 to 100\n",
        "                    img_name = f\"{str(j).zfill(3)}.png\"\n",
        "                    txt_name = f\"{str(j).zfill(3)}.txt\"\n",
        "\n",
        "                    img_path = os.path.join(folder_path, img_name)\n",
        "                    txt_path = os.path.join(folder_path, txt_name)\n",
        "\n",
        "                    if os.path.exists(img_path) and os.path.exists(txt_path):\n",
        "                        similarity_score, ocr_latex, correct_latex, elapsed_time = run_ocr_and_compare(img_path, txt_path)\n",
        "\n",
        "                        f.write(f\"Folder {folder_name}, Image {img_name}: Similarity = {similarity_score:.4f}\\n\")\n",
        "                        f.write(f\"OCR LaTeX: {ocr_latex}\\n\")\n",
        "                        f.write(f\"Correct LaTeX: {correct_latex}\\n\")\n",
        "                        f.write(f\"Time taken for OCR: {elapsed_time:.4f} seconds\\n\")\n",
        "\n",
        "                        # Provide feedback based on similarity score\n",
        "                        if similarity_score > 0.95:\n",
        "                            f.write(\"OCR output is highly accurate.\\n\")\n",
        "                        elif similarity_score > 0.85:\n",
        "                            f.write(\"OCR output is fairly accurate.\\n\")\n",
        "                        else:\n",
        "                            f.write(\"OCR output has significant differences.\\n\")\n",
        "\n",
        "                        f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "                        # Count the number of \"passed\" results (similarity > 0.9)\n",
        "                        if similarity_score > 0.9:\n",
        "                            passed_count += 1\n",
        "\n",
        "                        # Accumulate total time for calculating average and similarity score\n",
        "                        total_time += elapsed_time\n",
        "                        total_comparisons += 1\n",
        "                        total_similarity += similarity_score\n",
        "\n",
        "        # After processing all files, write the summary to the output file\n",
        "        if total_comparisons > 0:\n",
        "            avg_time = total_time / total_comparisons\n",
        "            avg_sim_score = total_similarity / total_comparisons\n",
        "        else:\n",
        "            avg_time = 0\n",
        "            avg_sim_score = 0\n",
        "\n",
        "        # Writing summary\n",
        "        f.write(\"\\nSummary:\\n\")\n",
        "        f.write(f\"Total number of comparisons: {total_comparisons}\\n\")\n",
        "        f.write(f\"Number of passed comparisons (similarity > 0.9): {passed_count}\\n\")\n",
        "        f.write(f\"Percentage of passed comparisons: {passed_count / total_comparisons * 100:.2f}%\\n\")\n",
        "        f.write(f\"Average similarity score: {avg_sim_score:.4f}\\n\")\n",
        "        f.write(f\"Average OCR response time: {avg_time:.4f} seconds\\n\")\n",
        "\n",
        "# Define the root directory where your dataset is stored\n",
        "dataset_dir = \"/content/SmallImage2LatexOCR/Dataset\"  # Change this path as needed\n",
        "\n",
        "# Define the output file\n",
        "output_file = \"MixTexOCR_Evaluation.txt\"\n",
        "\n",
        "# Process the entire dataset and write results to the output file\n",
        "process_dataset(dataset_dir, output_file)\n"
      ],
      "metadata": {
        "id": "pXUAhMN3D9pz"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}