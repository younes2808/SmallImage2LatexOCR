{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository(Evaluation DATASET)\n",
        "!git clone https://github.com/younes2808/SmallImage2LatexOCR.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEvWWebb5m5m",
        "outputId": "b20b02ac-5c3a-4d20-e327-c768f4e28024"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SmallImage2LatexOCR'...\n",
            "remote: Enumerating objects: 483, done.\u001b[K\n",
            "remote: Counting objects: 100% (483/483), done.\u001b[K\n",
            "remote: Compressing objects: 100% (471/471), done.\u001b[K\n",
            "remote: Total 483 (delta 18), reused 434 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (483/483), 570.93 KiB | 15.43 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing RapidLaTeXOCR\n",
        "!pip install rapid_latex_ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzVbls7L0-iG",
        "outputId": "3559b9a1-c03d-4f18-9f02-def09c1c7085"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapid_latex_ocr\n",
            "  Downloading rapid_latex_ocr-0.0.9-py3-none-any.whl.metadata (990 bytes)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (from rapid_latex_ocr) (1.20.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from rapid_latex_ocr) (0.19.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from rapid_latex_ocr) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from rapid_latex_ocr) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.11/dist-packages (from rapid_latex_ocr) (10.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from rapid_latex_ocr) (6.0.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from rapid_latex_ocr) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->rapid_latex_ocr) (0.27.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime->rapid_latex_ocr) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->rapid_latex_ocr) (25.1.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime->rapid_latex_ocr) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime->rapid_latex_ocr) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime->rapid_latex_ocr) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (4.12.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime->rapid_latex_ocr) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime->rapid_latex_ocr) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->rapid_latex_ocr) (2024.12.14)\n",
            "Downloading rapid_latex_ocr-0.0.9-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: rapid_latex_ocr\n",
            "Successfully installed rapid_latex_ocr-0.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import difflib\n",
        "import os\n",
        "from PIL import Image\n",
        "from rapid_latex_ocr import LaTeXOCR  # Import from rapid_latex_ocr\n",
        "import time\n",
        "\n",
        "\n",
        "def normalize_latex(latex_string):\n",
        "    \"\"\"\n",
        "    Normalize the LaTeX string by removing unnecessary spaces and ensuring consistent formatting.\n",
        "    \"\"\"\n",
        "    latex_string = latex_string.replace(\" \", \"\").replace(\"\\\\,\", \"\").replace(\"\\\\ \", \"\")\n",
        "    latex_string = latex_string.replace(\"...\", \"\\\\dots\")  # Normalize ellipsis\n",
        "    return latex_string\n",
        "\n",
        "\n",
        "def compare_latex(correct_latex, ocr_latex):\n",
        "    \"\"\"\n",
        "    Compare the correctness of the OCR output with the correct LaTeX expression.\n",
        "    \"\"\"\n",
        "    # Normalize both strings\n",
        "    normalized_correct = normalize_latex(correct_latex)\n",
        "    normalized_ocr = normalize_latex(ocr_latex)\n",
        "\n",
        "    # Use difflib to compare the two strings\n",
        "    diff = difflib.ndiff(normalized_correct, normalized_ocr)\n",
        "    similarity = sum(1 for c in diff if c[0] == \" \") / len(normalized_correct)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "\n",
        "def run_ocr_and_compare(img_path, txt_path, ocr_model):\n",
        "    \"\"\"\n",
        "    Run OCR on the image and compare the result with the corresponding LaTeX in the text file.\n",
        "    \"\"\"\n",
        "    # Start timer to measure OCR processing time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Read the image file as binary data\n",
        "    with open(img_path, \"rb\") as f:\n",
        "        image_data = f.read()\n",
        "\n",
        "    # Run OCR to get LaTeX output\n",
        "    ocr_latex, elapsed_time = ocr_model(image_data)\n",
        "\n",
        "    # End timer to calculate elapsed time\n",
        "    elapsed_time += time.time() - start_time\n",
        "\n",
        "    # Read the correct LaTeX from the corresponding .txt file\n",
        "    with open(txt_path, \"r\") as file:\n",
        "        correct_latex = file.read().strip()\n",
        "\n",
        "    # Compare the LaTeX strings\n",
        "    similarity_score = compare_latex(correct_latex, ocr_latex)\n",
        "\n",
        "    return similarity_score, ocr_latex, correct_latex, elapsed_time\n",
        "\n",
        "\n",
        "def process_dataset(dataset_dir, ocr_model, output_file):\n",
        "    \"\"\"\n",
        "    Process the entire dataset, comparing OCR results with ground truth LaTeX and logging results.\n",
        "    \"\"\"\n",
        "    passed_count = 0\n",
        "    total_time = 0\n",
        "    total_comparisons = 0\n",
        "    total_similarity = 0\n",
        "\n",
        "    # Open the output file to write results\n",
        "    with open(output_file, \"w\") as f:\n",
        "        # Loop through all folders from 000 to 100\n",
        "        for i in range(101):  # 0 to 100\n",
        "            folder_name = f\"{str(i).zfill(3)}\"  # Format as 000, 001, ..., 100\n",
        "            folder_path = os.path.join(dataset_dir, folder_name)\n",
        "\n",
        "            if os.path.isdir(folder_path):  # Process only directories\n",
        "                f.write(f\"Processing folder: {folder_name}\\n\")\n",
        "                # Loop through all image files from 000.png to 100.png\n",
        "                for j in range(101):  # 0 to 100\n",
        "                    img_name = f\"{str(j).zfill(3)}.png\"\n",
        "                    txt_name = f\"{str(j).zfill(3)}.txt\"\n",
        "\n",
        "                    img_path = os.path.join(folder_path, img_name)\n",
        "                    txt_path = os.path.join(folder_path, txt_name)\n",
        "\n",
        "                    if os.path.exists(img_path) and os.path.exists(txt_path):\n",
        "                        similarity_score, ocr_latex, correct_latex, elapsed_time = run_ocr_and_compare(\n",
        "                            img_path, txt_path, ocr_model\n",
        "                        )\n",
        "\n",
        "                        f.write(f\"Folder {folder_name}, Image {img_name}: Similarity = {similarity_score:.4f}\\n\")\n",
        "                        f.write(f\"OCR LaTeX: {ocr_latex}\\n\")\n",
        "                        f.write(f\"Correct LaTeX: {correct_latex}\\n\")\n",
        "                        f.write(f\"Time taken for OCR: {elapsed_time:.4f} seconds\\n\")\n",
        "\n",
        "                        # Provide feedback based on similarity score\n",
        "                        if similarity_score > 0.95:\n",
        "                            f.write(\"OCR output is highly accurate.\\n\")\n",
        "                        elif similarity_score > 0.85:\n",
        "                            f.write(\"OCR output is fairly accurate.\\n\")\n",
        "                        else:\n",
        "                            f.write(\"OCR output has significant differences.\\n\")\n",
        "\n",
        "                        f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "                        # Count the number of \"passed\" results (similarity > 0.9)\n",
        "                        if similarity_score > 0.9:\n",
        "                            passed_count += 1\n",
        "\n",
        "                        # Accumulate total time for calculating average and similarity score\n",
        "                        total_time += elapsed_time\n",
        "                        total_comparisons += 1\n",
        "                        total_similarity += similarity_score\n",
        "\n",
        "        # After processing all files, write the summary to the output file\n",
        "        if total_comparisons > 0:\n",
        "            avg_time = total_time / total_comparisons\n",
        "        else:\n",
        "            avg_time = 0\n",
        "\n",
        "        # Calculating average similarity score\n",
        "        avg_sim_score = total_similarity / total_comparisons\n",
        "\n",
        "        # Writing summary\n",
        "        f.write(\"\\nSummary:\\n\")\n",
        "        f.write(f\"Total number of comparisons: {total_comparisons}\\n\")\n",
        "        f.write(f\"Number of passed comparisons(similarity > 0.9): {passed_count}\\n\")\n",
        "        f.write(f\"Percentage of passed comparisons: {passed_count/total_comparisons:.2%}\\n\")\n",
        "        f.write(f\"Average similarity score: {avg_sim_score:.4f}\\n\")\n",
        "        f.write(f\"Average OCR response time: {avg_time:.4f} seconds\\n\")\n",
        "\n",
        "\n",
        "# Initialize the OCR model from rapid_latex_ocr\n",
        "model = LaTeXOCR()\n",
        "\n",
        "# Define the root directory where your dataset is stored\n",
        "dataset_dir = \"/content/SmallImage2LatexOCR/Dataset\"  # Change this path as needed\n",
        "\n",
        "# Define the output file\n",
        "output_file = \"LaTeXOCR_results.txt\"\n",
        "\n",
        "# Process the entire dataset and write results to the output file\n",
        "process_dataset(dataset_dir, model, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me9KLCfD1CZP",
        "outputId": "c91c5c8c-d48f-439c-f448-519249c2649c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download https://github.com/RapidAI/RapidLaTeXOCR/releases/download/v0.0.0/image_resizer.onnx to /usr/local/lib/python3.11/dist-packages/rapid_latex_ocr/models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image_resizer.onnx: 100%|██████████| 37.2M/37.2M [00:03<00:00, 12.5Mb/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download https://github.com/RapidAI/RapidLaTeXOCR/releases/download/v0.0.0/encoder.onnx to /usr/local/lib/python3.11/dist-packages/rapid_latex_ocr/models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "encoder.onnx: 100%|██████████| 84.9M/84.9M [00:22<00:00, 3.88Mb/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download https://github.com/RapidAI/RapidLaTeXOCR/releases/download/v0.0.0/decoder.onnx to /usr/local/lib/python3.11/dist-packages/rapid_latex_ocr/models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "decoder.onnx: 100%|██████████| 48.6M/48.6M [00:08<00:00, 5.86Mb/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download https://github.com/RapidAI/RapidLaTeXOCR/releases/download/v0.0.0/tokenizer.json to /usr/local/lib/python3.11/dist-packages/rapid_latex_ocr/models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizer.json: 100%|██████████| 23.6k/23.6k [00:00<00:00, 919kb/s]\n"
          ]
        }
      ]
    }
  ]
}